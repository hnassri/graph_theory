{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from geopy.geocoders import Nominatim\n",
    "pd.options.mode.copy_on_write = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lit le fichier des gares et filtrent sur les gares qui accueillent des voyageurs\n",
    "liste_gare = pd.read_csv(\"./liste-des-gares.csv\", sep=';')\n",
    "liste_gare = liste_gare.loc[liste_gare[\"VOYAGEURS\"] == \"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lit le fichier de stops\n",
    "liste_stops_ter = pd.read_csv(\"./export-ter-gtfs-last/stops.csv\", sep=\",\")\n",
    "liste_stops_ter = liste_stops_ter[[str.strip(x[:18]) == \"StopPoint:OCETrain\" for x in liste_stops_ter[\"stop_id\"]]]\n",
    "# liste_stops_ter[\"CODE_UIC\"] = [ int(x.split(\"-\")[-1]) for x in liste_stops_ter[\"stop_id\"]]\n",
    "# liste_stops_ter = pd.merge(liste_stops_ter, liste_gare, how=\"left\", on=\"CODE_UIC\")\n",
    "#liste_stops_ter[\"stop_name\"] = [city.strip().upper().replace(\" \", \"-\") for city in liste_stops_ter[\"stop_name\"]]\n",
    "# liste_stops_ter[\"city\"] = [geolocator.reverse(str(row.stop_lat) + \",\" + str(row.stop_lon)).raw[\"address\"][\"town\"].upper() for row in liste_stops_ter.itertuples()]\n",
    "# i = 0\n",
    "# for row in liste_stops_ter.itertuples():\n",
    "#     if i > 5: break\n",
    "#     i += 1\n",
    "#     geolocator = Nominatim(user_agent=\"my_geopy_app\")\n",
    "#     location = geolocator.reverse(str(row.stop_lat) + \",\" + str(row.stop_lon))\n",
    "#     print(location.raw[\"address\"])\n",
    "#     # row[\"city\"] = location.raw[\"address\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amenity': 'Amazon Hub',\n",
       " 'road': 'Allée des Tilleuls',\n",
       " 'village': 'Niederbronn-les-Bains',\n",
       " 'municipality': 'Haguenau-Wissembourg',\n",
       " 'county': 'Bas-Rhin',\n",
       " 'ISO3166-2-lvl6': 'FR-67',\n",
       " 'state': 'Grand Est',\n",
       " 'ISO3166-2-lvl4': 'FR-GES',\n",
       " 'region': 'France métropolitaine',\n",
       " 'postcode': '67110',\n",
       " 'country': 'France',\n",
       " 'country_code': 'fr'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geolocator = Nominatim(user_agent=\"my_geopy_app\")\n",
    "location = geolocator.reverse(\"48.9523850,7.63409000\")\n",
    "location.raw[\"address\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lit le fichier des temps d'arrêts des trains\n",
    "liste_stop_times_ter = pd.read_csv(\"./export-ter-gtfs-last/stop_times.csv\", sep=\",\")\n",
    "\n",
    "liste_stop_times_ter = liste_stop_times_ter[[str.strip(str(x)[:18]) == \"StopPoint:OCETrain\" for x in liste_stop_times_ter[\"stop_id\"]]]\n",
    "liste_stop_times_ter = pd.merge(liste_stop_times_ter, liste_stops_ter[[\"stop_id\", \"stop_name\"]], how=\"inner\", on=\"stop_id\")\n",
    "\n",
    "# col_trip_id_ter = liste_stop_times_ter[\"trip_id\"].unique()\n",
    "# liste_stop_times_ter[\"CODE_UIC\"] = [ int(x.split(\"-\")[-1]) for x in liste_stop_times_ter[\"stop_id\"]]\n",
    "# liste_stop_times_ter = pd.merge(liste_stop_times_ter, liste_gare, how=\"inner\", on=\"CODE_UIC\")\n",
    "# liste_stop_times_ter.COMMUNE.fillna(\"error\")\n",
    "# liste_stop_times_ter.loc[liste_stop_times_ter[\"COMMUNE\"] == \"error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trip_id', 'arrival_time', 'departure_time', 'stop_id', 'stop_sequence',\n",
       "       'stop_headsign', 'pickup_type', 'drop_off_type', 'shape_dist_traveled',\n",
       "       'stop_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_stop_times_ter.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52753\n",
      "819405\n",
      "5955580\n"
     ]
    }
   ],
   "source": [
    "liste_trips_ter = pd.read_csv(\"./export-ter-gtfs-last/trips.csv\", sep=\",\")\n",
    "liste_calendar_ter = pd.read_csv(\"./export-ter-gtfs-last/calendar_dates.csv\", sep=\",\")\n",
    "print(len(liste_trips_ter))\n",
    "\n",
    "liste_trips_ter = pd.merge(liste_trips_ter, liste_calendar_ter[[\"service_id\", \"date\"]], how=\"inner\", on=\"service_id\")\n",
    "\n",
    "print(len(liste_trips_ter))\n",
    "\n",
    "liste_stop_times_ter = pd.merge(liste_stop_times_ter, liste_trips_ter[[\"date\", \"trip_id\"]], how=\"inner\", on=\"trip_id\")\n",
    "\n",
    "print(len(liste_stop_times_ter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    05:00:00\n",
       "1    05:08:00\n",
       "2    05:30:00\n",
       "3    05:40:00\n",
       "4    05:49:00\n",
       "Name: arrival_time, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_stop_times_ter.arrival_time.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_stop_times_ter[\"date\"] = [datetime(int(str(row.date)[:4]), int(str(row.date)[4:6]),  int(str(row.date)[-2:]), 0 if int(str(row.arrival_time).split(\":\")[0]) >= 24 else int(str(row.arrival_time).split(\":\")[0]), int(str(row.arrival_time).split(\":\")[1])) for row in liste_stop_times_ter.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2024-11-18 05:00:00\n",
       "1   2024-11-18 05:08:00\n",
       "2   2024-11-18 05:30:00\n",
       "3   2024-11-18 05:40:00\n",
       "4   2024-11-18 05:49:00\n",
       "Name: date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_stop_times_ter.date.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_stop_times_ter[\"stop_name\"] = [name.upper() for name in liste_stop_times_ter[\"stop_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "['OBERNAI' 'GOXWILLER' 'BISCHOFFSHEIM' 'ROSHEIM' 'GERTWILLER' 'BARR'\n",
      " 'DORLISHEIM' 'MOLSHEIM' 'DACHSTEIN' 'DUTTLENHEIM' 'DUPPIGHEIM'\n",
      " 'ENTZHEIM AÉROPORT' 'LINGOLSHEIM' 'STRASBOURG ROETHIG' 'STRASBOURG'\n",
      " 'EICHHOFFEN' 'EPFIG' 'DAMBACH-LA-VILLE' 'SCHERWILLER' 'SÉLESTAT']\n",
      "['OCESN831701F3073049:2024-10-11T00:34:04Z;STRASBOURG;19/11/2024, 06:06:00', 'OCESN832902F3468357:2024-10-11T00:34:04Z;HAGUENAU;19/11/2024, 05:57:00']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'destination trouver'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depart = \"OBERNAI\"\n",
    "destination = \"HAGUENAU\"\n",
    "\n",
    "def check_destination(destination, layer):\n",
    "    return len(layer.loc[layer[\"stop_name\"] == destination]) > 0\n",
    "\n",
    "def path_back_propagation(layers, destination):\n",
    "    paths = []\n",
    "    city_to_fetch = destination\n",
    "    layers[-1].loc[layers[-1][\"stop_name\"] == city_to_fetch].to_csv(\"data_cleaned/test.csv\")\n",
    "    for layer in reversed(layers):\n",
    "        data = layer.loc[layer[\"stop_name\"] == city_to_fetch]\n",
    "        # print(len(data))\n",
    "        if len(data) == 0:\n",
    "            return \"error\"\n",
    "        data = data.iloc[0]\n",
    "        paths.append(data['current_path'])\n",
    "        if data[\"previous_path\"] == \"\":\n",
    "            return paths[::-1]\n",
    "        city_to_fetch = data[\"previous_path\"].split(';')[0]\n",
    "        # print(data[\"previous_path\"])\n",
    "\n",
    "def filter_direction_trip(data, namesList, start_date=False):\n",
    "    find_name = False\n",
    "    trip_id = \"\"\n",
    "    end_date = \"\"\n",
    "    default_value = False\n",
    "    if start_date != False:\n",
    "        end_date = start_date + timedelta(days=1)\n",
    "        default_value = True\n",
    "    data = data.sort_values(by=[\"trip_id\", \"stop_sequence\"])\n",
    "    for index, row in data.iterrows():\n",
    "        if not default_value:\n",
    "            date_str = row.previous_path.split(';')[-1]\n",
    "            date = datetime.strptime(date_str, \"%d/%m/%Y, %H:%M:%S\")\n",
    "            start_date = date + timedelta(minutes=5)\n",
    "            end_date = start_date + timedelta(days=1)\n",
    "\n",
    "        if row.trip_id != trip_id:\n",
    "            trip_id = row.trip_id\n",
    "            find_name = False\n",
    "        if row.stop_name in namesList and (row.date >= start_date and row.date <= end_date):\n",
    "            find_name = True\n",
    "        data.loc[index, 'isDirectionOk'] = \"ok\" if find_name else \"ko\"\n",
    "    data.to_csv(\"data_cleaned/test-ok.csv\")\n",
    "    data = data.drop(data[data.isDirectionOk == \"ko\"].index)\n",
    "    data.to_csv(\"data_cleaned/test-drop.csv\")\n",
    "    return data\n",
    "\n",
    "def shortest_path(depart, destination, start_date):\n",
    "    layers = []\n",
    "    not_founded = 0 # vérifie qu'on a pas trouvé un chemin vers l'arrivée\n",
    "    liste_stop_times_ter[\"isDirectionOk\"] = \"\"\n",
    "\n",
    "    start_date = datetime.strptime(start_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    end_date = start_date + timedelta(days=1)\n",
    "    date_mask = (liste_stop_times_ter[\"date\"] > start_date) & (liste_stop_times_ter[\"date\"] < end_date)\n",
    "\n",
    "    trips_id = set(liste_stop_times_ter.loc[(liste_stop_times_ter[\"stop_name\"] == depart) & date_mask][\"trip_id\"])\n",
    "    layer = liste_stop_times_ter.loc[(liste_stop_times_ter[\"trip_id\"].isin(trips_id)) & date_mask]\n",
    "    \n",
    "    layer[\"previous_path\"] = \"\"\n",
    "    layer = filter_direction_trip(layer, [depart], start_date)  \n",
    "    layer = layer.sort_values(by=\"date\").drop_duplicates(subset=[\"stop_id\"])\n",
    "\n",
    "    \n",
    "    layer[\"current_path\"] = layer[\"trip_id\"] + \";\" + layer[\"stop_name\"] + \";\" + layer[\"date\"].dt.strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
    "\n",
    "    layers.append(layer)\n",
    "    layer.to_csv(\"data_cleaned/layer_1.csv\")\n",
    "\n",
    "    while not_founded < 100:\n",
    "        if check_destination(destination, layers[-1]):\n",
    "            print(path_back_propagation(layers, destination))\n",
    "            return \"destination trouver\"\n",
    "        \n",
    "        filtered_data = liste_stop_times_ter.loc[(liste_stop_times_ter[\"stop_name\"].isin(layers[-1][\"stop_name\"].unique())) & date_mask]\n",
    "\n",
    "        paths = {}\n",
    "        for row in filtered_data.itertuples():\n",
    "            paths[row.trip_id] = str(row.stop_name) + \";\" + row.date.strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
    "        # start_date = datetime.strptime(start_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "        # end_date = start_date + timedelta(days=1)\n",
    "        # date_mask = (liste_stop_times_ter[\"date\"] > start_date) & (liste_stop_times_ter[\"date\"] < end_date)\n",
    "        \n",
    "        trips_id = set(filtered_data[\"trip_id\"]) - set(layers[-1][\"trip_id\"])\n",
    "        print(len(layers[-1][\"stop_name\"].unique()))\n",
    "        layer = liste_stop_times_ter.loc[(liste_stop_times_ter[\"trip_id\"].isin(trips_id)) & date_mask]\n",
    "        \n",
    "        layer[\"previous_path\"] = [paths[data.trip_id] for data in layer.itertuples()]\n",
    "        layer.to_csv(\"data_cleaned/final_layer-2.csv\")\n",
    "        print(layers[-1][\"stop_name\"].unique())\n",
    "        layer = filter_direction_trip(layer, layers[-1][\"stop_name\"].unique())\n",
    "        layer.to_csv(\"data_cleaned/final_layer-4.csv\")\n",
    "\n",
    "        layer = layer.sort_values(by=\"date\").drop_duplicates(subset=[\"stop_id\"])\n",
    "        layer.to_csv(\"data_cleaned/final_layer-3.csv\")\n",
    "        \n",
    "        \n",
    "        layer[\"current_path\"] = layer[\"trip_id\"] + \";\" + layer[\"stop_name\"] + \";\" + layer[\"date\"].dt.strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
    "        layer.to_csv(\"data_cleaned/final_layer.csv\")\n",
    "        layers.append(layer)\n",
    "        \n",
    "        not_founded += 1\n",
    "    return \"not found excedeed 100 search\"\n",
    "shortest_path(depart, destination, \"2024-11-19 05:00:00\")\n",
    "# trips_id = set(liste_stop_times_ter.loc[liste_stop_times_ter[\"COMMUNE\"] == depart][\"trip_id\"].unique())\n",
    "# print(check_destination(destination,liste_stop_times_ter[liste_stop_times_ter[\"trip_id\"].isin(trips_id)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-19 08:27:00\n",
      "2024-11-19 08:32:00\n",
      "2024-11-20 08:32:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "date = datetime.strptime(\"19/11/2024, 08:27:00\", \"%d/%m/%Y, %H:%M:%S\")\n",
    "print(date)\n",
    "start_date = date + timedelta(minutes=5)\n",
    "print(start_date)\n",
    "end_date = start_date + timedelta(days=1)\n",
    "print(end_date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
